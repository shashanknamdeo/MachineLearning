{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d04eb252-8fed-4586-bd61-3fb0c9b079eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import idx2numpy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras import backend\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Activation\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Conv2D\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras import metrics\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "DATA_DIR = r'C:\\WindowsData\\ShirishPC\\MachineLearning\\MLProjects\\MNIST\\Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08ebb9b2-6a7c-4705-a1d8-5dc302b9d3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_images = idx2numpy.convert_from_file(os.path.join(DATA_DIR, 'train-images.idx3-ubyte'))\n",
    "mnist_train_labels = idx2numpy.convert_from_file(os.path.join(DATA_DIR, 'train-labels.idx1-ubyte'))\n",
    "\n",
    "mnist_test_images = idx2numpy.convert_from_file(os.path.join(DATA_DIR, 't10k-images.idx3-ubyte'))\n",
    "mnist_test_labels = idx2numpy.convert_from_file(os.path.join(DATA_DIR, 't10k-labels.idx1-ubyte'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e76f57e7-1a73-4c1b-ab38-d1cdecdddb69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3cb42113-7d2f-4e65-ac64-d1c2771649ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = mnist_train_images[:10000]\n",
    "X_test  = mnist_test_images\n",
    "\n",
    "Y_train = mnist_train_labels[:10000]\n",
    "Y_test  = mnist_test_labels\n",
    "\n",
    "# reshape dataset to have a single channel\n",
    "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d23b7d6-c913-4fa4-9f66-c6ee5634be27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAZoUlEQVR4nO3df0xV9/3H8df11622cB0iXJhXh7bVrVaWOUXS1q+dRGGJ8Vdb+2OJNkajw2bKujYurdZtCZvNrGnj9J9N16T+XKqmJnNRLJiu4CLVGLONCGMDI+Bq4r2I9Wrk8/2DeNdbpXqv9/LmwvORnETuPYfz9vTsPne4x4vHOecEAEAPG2A9AACgfyJAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADAxCDrAb6qs7NTFy5cUFpamjwej/U4AIAYOefU3t6u3NxcDRjQ/XVOrwvQhQsXFAgErMcAANyn5uZmjRo1qtvne12A0tLSJHUNnp6ebjwNACBWoVBIgUAg8nrenaQFaMuWLXr77bfV2tqq/Px8vffee5o6depdt7v1Y7f09HQCBAAp7G5voyTlJoQ9e/aorKxM69ev12effab8/HzNnj1bFy9eTMbuAAApKCkB2rRpk5YtW6aXX35Z3/nOd7Rt2zYNGzZMf/jDH5KxOwBACkp4gK5fv67a2loVFRX9bycDBqioqEjV1dW3rR8OhxUKhaIWAEDfl/AAff7557p586ays7OjHs/OzlZra+tt65eXl8vn80UW7oADgP7B/B+irl27VsFgMLI0NzdbjwQA6AEJvwsuMzNTAwcOVFtbW9TjbW1t8vv9t63v9Xrl9XoTPQYAoJdL+BXQkCFDNHnyZFVUVEQe6+zsVEVFhQoLCxO9OwBAikrKvwMqKyvT4sWL9f3vf19Tp07V5s2b1dHRoZdffjkZuwMApKCkBGjRokX673//q3Xr1qm1tVXf/e53dfjw4dtuTAAA9F8e55yzHuLLQqGQfD6fgsEgn4QAACnoXl/Hze+CAwD0TwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwETCA/TWW2/J4/FELRMmTEj0bgAAKW5QMr7pY489pqNHj/5vJ4OSshsAQApLShkGDRokv9+fjG8NAOgjkvIe0Llz55Sbm6uxY8fqpZdeUlNTU7frhsNhhUKhqAUA0PclPEAFBQXasWOHDh8+rK1bt6qxsVFPPfWU2tvb77h+eXm5fD5fZAkEAokeCQDQC3mccy6ZO7h8+bLGjBmjTZs2aenSpbc9Hw6HFQ6HI1+HQiEFAgEFg0Glp6cnczQAQBKEQiH5fL67vo4n/e6A4cOH69FHH1V9ff0dn/d6vfJ6vckeAwDQyyT93wFduXJFDQ0NysnJSfauAAApJOEBevXVV1VVVaV///vf+vTTTzV//nwNHDhQL7zwQqJ3BQBIYQn/Edz58+f1wgsv6NKlSxo5cqSefPJJ1dTUaOTIkYneFQAghSU8QLt37070twQA9EF8FhwAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYCLpv5AOsNDc3BzXdu+8807M2/zpT3+KeZt454vVs88+G9d2v/3tb2PeJhAIxLUv9F9cAQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEn4aNHrV3796Yt4nn06b37dsX8zaSNG3atJi3eeaZZ3pkP/FYtGhRj+xHiu+/Lfo3roAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABN8GCni9txzz8W8TTwfEvrss8/GvM2nn34a8zaSVFhYGNd2PaG6urrH9rVmzZoe2xf6L66AAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATfBgp4tZTHyy6d+/emLfp7TZt2hTzNps3b455m3g/VLQ3fygr+g6ugAAAJggQAMBEzAE6fvy45syZo9zcXHk8Hh04cCDqeeec1q1bp5ycHA0dOlRFRUU6d+5couYFAPQRMQeoo6ND+fn52rJlyx2f37hxo959911t27ZNJ06c0IMPPqjZs2fr2rVr9z0sAKDviPkmhJKSEpWUlNzxOeecNm/erDfeeENz586VJL3//vvKzs7WgQMH9Pzzz9/ftACAPiOh7wE1NjaqtbVVRUVFkcd8Pp8KCgq6/XXC4XBYoVAoagEA9H0JDVBra6skKTs7O+rx7OzsyHNfVV5eLp/PF1kCgUAiRwIA9FLmd8GtXbtWwWAwsjQ3N1uPBADoAQkNkN/vlyS1tbVFPd7W1hZ57qu8Xq/S09OjFgBA35fQAOXl5cnv96uioiLyWCgU0okTJ/iX1QCAKDHfBXflyhXV19dHvm5sbNTp06eVkZGh0aNHa/Xq1frVr36lRx55RHl5eXrzzTeVm5urefPmJXJuAECKizlAJ0+e1NNPPx35uqysTJK0ePFi7dixQ6+99po6Ojq0fPlyXb58WU8++aQOHz6sBx54IHFTAwBSnsc556yH+LJQKCSfz6dgMMj7Qb3cc889F/M2PfUBpj0pnr9TT4n3rtKmpqYET4L+5F5fx83vggMA9E8ECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwEfOvYwBu2bt3b8zb3Pr1HbE4f/58zNv0pD179sS8TU/9gsbRo0fHtV08n3Qez/mA/o0rIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADAhMc556yH+LJQKCSfz6dgMKj09HTrcYCU5vF4emxfveylBIbu9XWcKyAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADARMwBOn78uObMmaPc3Fx5PB4dOHAg6vklS5bI4/FELcXFxYmaFwDQR8QcoI6ODuXn52vLli3drlNcXKyWlpbIsmvXrvsaEgDQ9wyKdYOSkhKVlJR87Tper1d+vz/uoQAAfV9S3gOqrKxUVlaWxo8fr5UrV+rSpUvdrhsOhxUKhaIWAEDfl/AAFRcX6/3331dFRYV+85vfqKqqSiUlJbp58+Yd1y8vL5fP54ssgUAg0SMBAHohj3POxb2xx6P9+/dr3rx53a7zr3/9S+PGjdPRo0c1c+bM254Ph8MKh8ORr0OhkAKBgILBoNLT0+MdDYC6/jfaU+7jpQR9TCgUks/nu+vreNJvwx47dqwyMzNVX19/x+e9Xq/S09OjFgBA35f0AJ0/f16XLl1STk5OsncFAEghMd8Fd+XKlairmcbGRp0+fVoZGRnKyMjQhg0btHDhQvn9fjU0NOi1117Tww8/rNmzZyd0cABAaos5QCdPntTTTz8d+bqsrEyStHjxYm3dulVnzpzRH//4R12+fFm5ubmaNWuWfvnLX8rr9SZuagBAyos5QDNmzPjaNxv/8pe/3NdAAOxxNyp6Ap8FBwAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMxfxo2gL7vmWeesR4B/QBXQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACT6MFEgRe/fu7bF9TZs2rcf2hf6LKyAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgIlB1gMAuDfnz5/vsX0VFhb22L7Qf3EFBAAwQYAAACZiClB5ebmmTJmitLQ0ZWVlad68eaqrq4ta59q1ayotLdWIESP00EMPaeHChWpra0vo0ACA1BdTgKqqqlRaWqqamhodOXJEN27c0KxZs9TR0RFZZ82aNfroo4+0b98+VVVV6cKFC1qwYEHCBwcApLaYbkI4fPhw1Nc7duxQVlaWamtrNX36dAWDQf3+97/Xzp079YMf/ECStH37dn37299WTU2Npk2blrjJAQAp7b7eAwoGg5KkjIwMSVJtba1u3LihoqKiyDoTJkzQ6NGjVV1dfcfvEQ6HFQqFohYAQN8Xd4A6Ozu1evVqPfHEE5o4caIkqbW1VUOGDNHw4cOj1s3OzlZra+sdv095ebl8Pl9kCQQC8Y4EAEghcQeotLRUZ8+e1e7du+9rgLVr1yoYDEaW5ubm+/p+AIDUENc/RF21apUOHTqk48ePa9SoUZHH/X6/rl+/rsuXL0ddBbW1tcnv99/xe3m9Xnm93njGAACksJiugJxzWrVqlfbv369jx44pLy8v6vnJkydr8ODBqqioiDxWV1enpqYm/mU1ACBKTFdApaWl2rlzpw4ePKi0tLTI+zo+n09Dhw6Vz+fT0qVLVVZWpoyMDKWnp+uVV15RYWEhd8ABAKLEFKCtW7dKkmbMmBH1+Pbt27VkyRJJ0jvvvKMBAwZo4cKFCofDmj17tn73u98lZFgAQN/hcc456yG+LBQKyefzKRgMKj093XocoNeI58fYNTU1ce2rl70sIMXc6+s4nwUHADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAE3H9RlQAPS/eT7YGeiuugAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmYgpQeXm5pkyZorS0NGVlZWnevHmqq6uLWmfGjBnyeDxRy4oVKxI6NAAg9cUUoKqqKpWWlqqmpkZHjhzRjRs3NGvWLHV0dEStt2zZMrW0tESWjRs3JnRoAEDqGxTLyocPH476eseOHcrKylJtba2mT58eeXzYsGHy+/2JmRAA0Cfd13tAwWBQkpSRkRH1+AcffKDMzExNnDhRa9eu1dWrV7v9HuFwWKFQKGoBAPR9MV0BfVlnZ6dWr16tJ554QhMnTow8/uKLL2rMmDHKzc3VmTNn9Prrr6uurk4ffvjhHb9PeXm5NmzYEO8YAIAU5XHOuXg2XLlypf785z/rk08+0ahRo7pd79ixY5o5c6bq6+s1bty4254Ph8MKh8ORr0OhkAKBgILBoNLT0+MZDeiTPB5Pj+0rzpcFQFLX67jP57vr63hcV0CrVq3SoUOHdPz48a+NjyQVFBRIUrcB8nq98nq98YwBAEhhMQXIOadXXnlF+/fvV2VlpfLy8u66zenTpyVJOTk5cQ0IAOibYgpQaWmpdu7cqYMHDyotLU2tra2SJJ/Pp6FDh6qhoUE7d+7UD3/4Q40YMUJnzpzRmjVrNH36dE2aNCkpfwEAQGqK6T2g7n4GvX37di1ZskTNzc360Y9+pLNnz6qjo0OBQEDz58/XG2+8cc/v59zrzw6B/ob3gJAqkvIe0N1OykAgoKqqqli+JQCgn4r7NmwAPWvNmjUxb3P+/PkkTAIkBh9GCgAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCY4MNIgRSxadMm6xGAhOIKCABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgIle91lwzjlJUigUMp4EABCPW6/ft17Pu9PrAtTe3i5JCgQCxpMAAO5He3u7fD5ft8973N0S1cM6Ozt14cIFpaWlyePxRD0XCoUUCATU3Nys9PR0owntcRy6cBy6cBy6cBy69Ibj4JxTe3u7cnNzNWBA9+/09LoroAEDBmjUqFFfu056enq/PsFu4Th04Th04Th04Th0sT4OX3flcws3IQAATBAgAICJlAqQ1+vV+vXr5fV6rUcxxXHownHownHownHokkrHodfdhAAA6B9S6goIANB3ECAAgAkCBAAwQYAAACZSJkBbtmzRt771LT3wwAMqKCjQ3/72N+uRetxbb70lj8cTtUyYMMF6rKQ7fvy45syZo9zcXHk8Hh04cCDqeeec1q1bp5ycHA0dOlRFRUU6d+6czbBJdLfjsGTJktvOj+LiYpthk6S8vFxTpkxRWlqasrKyNG/ePNXV1UWtc+3aNZWWlmrEiBF66KGHtHDhQrW1tRlNnBz3chxmzJhx2/mwYsUKo4nvLCUCtGfPHpWVlWn9+vX67LPPlJ+fr9mzZ+vixYvWo/W4xx57TC0tLZHlk08+sR4p6To6OpSfn68tW7bc8fmNGzfq3Xff1bZt23TixAk9+OCDmj17tq5du9bDkybX3Y6DJBUXF0edH7t27erBCZOvqqpKpaWlqqmp0ZEjR3Tjxg3NmjVLHR0dkXXWrFmjjz76SPv27VNVVZUuXLigBQsWGE6dePdyHCRp2bJlUefDxo0bjSbuhksBU6dOdaWlpZGvb9686XJzc115ebnhVD1v/fr1Lj8/33oMU5Lc/v37I193dnY6v9/v3n777chjly9fdl6v1+3atctgwp7x1ePgnHOLFy92c+fONZnHysWLF50kV1VV5Zzr+m8/ePBgt2/fvsg6//jHP5wkV11dbTVm0n31ODjn3P/93/+5n/zkJ3ZD3YNefwV0/fp11dbWqqioKPLYgAEDVFRUpOrqasPJbJw7d065ubkaO3asXnrpJTU1NVmPZKqxsVGtra1R54fP51NBQUG/PD8qKyuVlZWl8ePHa+XKlbp06ZL1SEkVDAYlSRkZGZKk2tpa3bhxI+p8mDBhgkaPHt2nz4evHodbPvjgA2VmZmrixIlau3atrl69ajFet3rdh5F+1eeff66bN28qOzs76vHs7Gz985//NJrKRkFBgXbs2KHx48erpaVFGzZs0FNPPaWzZ88qLS3NejwTra2tknTH8+PWc/1FcXGxFixYoLy8PDU0NOjnP/+5SkpKVF1drYEDB1qPl3CdnZ1avXq1nnjiCU2cOFFS1/kwZMgQDR8+PGrdvnw+3Ok4SNKLL76oMWPGKDc3V2fOnNHrr7+uuro6ffjhh4bTRuv1AcL/lJSURP48adIkFRQUaMyYMdq7d6+WLl1qOBl6g+effz7y58cff1yTJk3SuHHjVFlZqZkzZxpOlhylpaU6e/Zsv3gf9Ot0dxyWL18e+fPjjz+unJwczZw5Uw0NDRo3blxPj3lHvf5HcJmZmRo4cOBtd7G0tbXJ7/cbTdU7DB8+XI8++qjq6+utRzFz6xzg/Ljd2LFjlZmZ2SfPj1WrVunQoUP6+OOPo359i9/v1/Xr13X58uWo9fvq+dDdcbiTgoICSepV50OvD9CQIUM0efJkVVRURB7r7OxURUWFCgsLDSezd+XKFTU0NCgnJ8d6FDN5eXny+/1R50coFNKJEyf6/flx/vx5Xbp0qU+dH845rVq1Svv379exY8eUl5cX9fzkyZM1ePDgqPOhrq5OTU1Nfep8uNtxuJPTp09LUu86H6zvgrgXu3fvdl6v1+3YscP9/e9/d8uXL3fDhw93ra2t1qP1qJ/+9KeusrLSNTY2ur/+9a+uqKjIZWZmuosXL1qPllTt7e3u1KlT7tSpU06S27Rpkzt16pT7z3/+45xz7te//rUbPny4O3jwoDtz5oybO3euy8vLc1988YXx5In1dcehvb3dvfrqq666uto1Nja6o0ePuu9973vukUcecdeuXbMePWFWrlzpfD6fq6ysdC0tLZHl6tWrkXVWrFjhRo8e7Y4dO+ZOnjzpCgsLXWFhoeHUiXe341BfX+9+8YtfuJMnT7rGxkZ38OBBN3bsWDd9+nTjyaOlRICcc+69995zo0ePdkOGDHFTp051NTU11iP1uEWLFrmcnBw3ZMgQ981vftMtWrTI1dfXW4+VdB9//LGTdNuyePFi51zXrdhvvvmmy87Odl6v182cOdPV1dXZDp0EX3ccrl696mbNmuVGjhzpBg8e7MaMGeOWLVvW5/5P2p3+/pLc9u3bI+t88cUX7sc//rH7xje+4YYNG+bmz5/vWlpa7IZOgrsdh6amJjd9+nSXkZHhvF6ve/jhh93PfvYzFwwGbQf/Cn4dAwDARK9/DwgA0DcRIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACb+H5grdRTKNCVuAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[304], cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "712bf85c-27bd-4fa3-90a3-08bd5d7f9c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoder = OneHotEncoder()\n",
    "Y_train = one_hot_encoder.fit_transform(Y_train.reshape(-1, 1)).toarray()\n",
    "Y_test = one_hot_encoder.fit_transform(Y_test.reshape(-1, 1)).toarray()\n",
    "\n",
    "# convert from integers to floats\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# Normalize to range 0-1\n",
    "X_train_normalized = X_train / 255.0\n",
    "X_test_normalized = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7fbd8945-322b-48c2-a30d-56a0e577f6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_9 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 13, 13, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 5408)              0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 100)               540900    \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 542,230\n",
      "Trainable params: 542,230\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.3900 - accuracy: 0.8795 - val_loss: 35.0017 - val_accuracy: 0.9248\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.2429 - accuracy: 0.9237\n",
      "[0.24294638633728027, 0.9236999750137329]\n",
      "313/313 [==============================] - 2s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
    "model1.add(MaxPooling2D((2, 2)))\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
    "model1.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model1.summary()\n",
    "\n",
    "optimizer_sgd = SGD(learning_rate=0.01, momentum=0.9)\n",
    "model1.compile(optimizer=optimizer_sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model1.fit(x=X_train_normalized, y=Y_train, batch_size=32, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=(X_test, Y_test), shuffle=True, \n",
    "    class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None)\n",
    "\n",
    "print(model1.evaluate(x=X_test_normalized, y=Y_test, batch_size=32, verbose=1))\n",
    "# [2.3018434047698975, 0.11349999904632568] -> Non-Normalized Data\n",
    "# [0.041888754814863205, 0.9860000014305115] -> -> Psot Normalized Data\n",
    "\n",
    "Y_predict = model1.predict(x=X_test, batch_size=None, verbose=1, steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f772ee21-15a6-40e7-b462-bf0badffad6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_11 (Conv2D)          (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 13, 13, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 5408)              0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 100)               540900    \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 542,230\n",
      "Trainable params: 542,230\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.4032 - accuracy: 0.8770 - val_loss: 33.4549 - val_accuracy: 0.9309\n",
      "Epoch 2/20\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.1577 - accuracy: 0.9537 - val_loss: 25.4844 - val_accuracy: 0.9522\n",
      "Epoch 3/20\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.0979 - accuracy: 0.9700 - val_loss: 23.0094 - val_accuracy: 0.9586\n",
      "Epoch 4/20\n",
      "313/313 [==============================] - 7s 24ms/step - loss: 0.0679 - accuracy: 0.9784 - val_loss: 29.1953 - val_accuracy: 0.9491\n",
      "Epoch 5/20\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.0460 - accuracy: 0.9870 - val_loss: 34.6193 - val_accuracy: 0.9497\n",
      "Epoch 6/20\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.0315 - accuracy: 0.9918 - val_loss: 29.8739 - val_accuracy: 0.9566\n",
      "Epoch 7/20\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.0197 - accuracy: 0.9962 - val_loss: 29.7376 - val_accuracy: 0.9558\n",
      "Epoch 8/20\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.0132 - accuracy: 0.9974 - val_loss: 25.3021 - val_accuracy: 0.9647\n",
      "Epoch 9/20\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.0085 - accuracy: 0.9988 - val_loss: 26.5524 - val_accuracy: 0.9647\n",
      "Epoch 10/20\n",
      "313/313 [==============================] - 7s 24ms/step - loss: 0.0060 - accuracy: 0.9996 - val_loss: 25.8729 - val_accuracy: 0.9667\n",
      "Epoch 11/20\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.0042 - accuracy: 0.9999 - val_loss: 26.1190 - val_accuracy: 0.9682\n",
      "Epoch 12/20\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.0035 - accuracy: 0.9998 - val_loss: 27.0600 - val_accuracy: 0.9672\n",
      "Epoch 13/20\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 27.2261 - val_accuracy: 0.9685\n",
      "Epoch 14/20\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 28.2924 - val_accuracy: 0.9665\n",
      "Epoch 15/20\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 27.5747 - val_accuracy: 0.9691\n",
      "Epoch 16/20\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 27.2443 - val_accuracy: 0.9696\n",
      "Epoch 17/20\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 28.4387 - val_accuracy: 0.9686\n",
      "Epoch 18/20\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 28.7260 - val_accuracy: 0.9687\n",
      "Epoch 19/20\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 29.7045 - val_accuracy: 0.9683\n",
      "Epoch 20/20\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 30.6005 - val_accuracy: 0.9671\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.1031 - accuracy: 0.9748\n",
      "[0.10312486439943314, 0.9747999906539917]\n",
      "313/313 [==============================] - 2s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
    "model1.add(MaxPooling2D((2, 2)))\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
    "model1.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model1.summary()\n",
    "\n",
    "optimizer_sgd = SGD(learning_rate=0.01, momentum=0.9)\n",
    "model1.compile(optimizer=optimizer_sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model1.fit(x=X_train_normalized, y=Y_train, batch_size=32, epochs=20, verbose=1, callbacks=None, validation_split=0.0, validation_data=(X_test, Y_test), shuffle=True, \n",
    "    class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None)\n",
    "\n",
    "print(model1.evaluate(x=X_test_normalized, y=Y_test, batch_size=32, verbose=1))\n",
    "# [2.3018434047698975, 0.11349999904632568] -> Non-Normalized Data\n",
    "# [0.041888754814863205, 0.9860000014305115] -> -> Psot Normalized Data\n",
    "\n",
    "Y_predict = model1.predict(x=X_test, batch_size=None, verbose=1, steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "327ace35-7eca-4424-84cd-80395ecca1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_25 (Conv2D)          (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_20 (MaxPoolin  (None, 13, 13, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_21 (MaxPoolin  (None, 5, 5, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_17 (Flatten)        (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 100)               160100    \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 179,926\n",
      "Trainable params: 179,926\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "313/313 [==============================] - 11s 31ms/step - loss: 0.3211 - accuracy: 0.8970 - val_loss: 21.8516 - val_accuracy: 0.9535\n",
      "Epoch 2/20\n",
      "313/313 [==============================] - 9s 29ms/step - loss: 0.1015 - accuracy: 0.9688 - val_loss: 18.0107 - val_accuracy: 0.9615\n",
      "Epoch 3/20\n",
      "313/313 [==============================] - 9s 29ms/step - loss: 0.0612 - accuracy: 0.9813 - val_loss: 20.3150 - val_accuracy: 0.9633\n",
      "Epoch 4/20\n",
      "313/313 [==============================] - 9s 29ms/step - loss: 0.0441 - accuracy: 0.9867 - val_loss: 15.1042 - val_accuracy: 0.9753\n",
      "Epoch 5/20\n",
      "313/313 [==============================] - 9s 30ms/step - loss: 0.0309 - accuracy: 0.9901 - val_loss: 13.9546 - val_accuracy: 0.9777\n",
      "Epoch 6/20\n",
      "313/313 [==============================] - 9s 30ms/step - loss: 0.0206 - accuracy: 0.9937 - val_loss: 15.3080 - val_accuracy: 0.9771\n",
      "Epoch 7/20\n",
      "313/313 [==============================] - 9s 29ms/step - loss: 0.0137 - accuracy: 0.9959 - val_loss: 22.5362 - val_accuracy: 0.9711\n",
      "Epoch 8/20\n",
      "313/313 [==============================] - 9s 29ms/step - loss: 0.0082 - accuracy: 0.9979 - val_loss: 18.8055 - val_accuracy: 0.9746\n",
      "Epoch 9/20\n",
      "313/313 [==============================] - 9s 30ms/step - loss: 0.0053 - accuracy: 0.9989 - val_loss: 14.3300 - val_accuracy: 0.9822\n",
      "Epoch 10/20\n",
      "313/313 [==============================] - 10s 33ms/step - loss: 0.0019 - accuracy: 0.9999 - val_loss: 14.9783 - val_accuracy: 0.9813\n",
      "Epoch 11/20\n",
      "313/313 [==============================] - 10s 33ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 14.8950 - val_accuracy: 0.9821\n",
      "Epoch 12/20\n",
      "313/313 [==============================] - 10s 32ms/step - loss: 8.6531e-04 - accuracy: 1.0000 - val_loss: 15.7207 - val_accuracy: 0.9821\n",
      "Epoch 13/20\n",
      "313/313 [==============================] - 10s 32ms/step - loss: 6.8519e-04 - accuracy: 1.0000 - val_loss: 15.7400 - val_accuracy: 0.9829\n",
      "Epoch 14/20\n",
      "313/313 [==============================] - 10s 33ms/step - loss: 5.7147e-04 - accuracy: 1.0000 - val_loss: 15.5227 - val_accuracy: 0.9835\n",
      "Epoch 15/20\n",
      "313/313 [==============================] - 10s 31ms/step - loss: 5.1126e-04 - accuracy: 1.0000 - val_loss: 16.7105 - val_accuracy: 0.9820\n",
      "Epoch 16/20\n",
      "313/313 [==============================] - 9s 30ms/step - loss: 4.8172e-04 - accuracy: 1.0000 - val_loss: 15.9703 - val_accuracy: 0.9827\n",
      "Epoch 17/20\n",
      "313/313 [==============================] - 9s 30ms/step - loss: 4.2123e-04 - accuracy: 1.0000 - val_loss: 16.1532 - val_accuracy: 0.9830\n",
      "Epoch 18/20\n",
      "313/313 [==============================] - 9s 30ms/step - loss: 3.8168e-04 - accuracy: 1.0000 - val_loss: 16.6701 - val_accuracy: 0.9829\n",
      "Epoch 19/20\n",
      "313/313 [==============================] - 9s 29ms/step - loss: 3.4808e-04 - accuracy: 1.0000 - val_loss: 16.5728 - val_accuracy: 0.9836\n",
      "Epoch 20/20\n",
      "313/313 [==============================] - 9s 29ms/step - loss: 3.2025e-04 - accuracy: 1.0000 - val_loss: 16.8472 - val_accuracy: 0.9835\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.0612 - accuracy: 0.9843\n",
      "[0.0611855648458004, 0.9843000173568726]\n",
      "313/313 [==============================] - 2s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Input(shape=(28,28,1)))\n",
    "\n",
    "model1.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
    "model1.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model1.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
    "model1.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
    "model1.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model1.summary()\n",
    "\n",
    "\n",
    "optimizer_sgd = SGD(learning_rate=0.01, momentum=0.9)\n",
    "model1.compile(optimizer=optimizer_sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model1.fit(x=X_train_normalized, y=Y_train, batch_size=32, epochs=20, verbose=1, callbacks=None, validation_split=0.0, validation_data=(X_test, Y_test), shuffle=True, \n",
    "    class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None)\n",
    "\n",
    "print(model1.evaluate(x=X_test_normalized, y=Y_test, batch_size=32, verbose=1))\n",
    "# [2.3018434047698975, 0.11349999904632568] -> Non-Normalized Data\n",
    "# [0.041888754814863205, 0.9860000014305115] -> -> Psot Normalized Data\n",
    "\n",
    "Y_predict = model1.predict(x=X_test, batch_size=None, verbose=1, steps=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
